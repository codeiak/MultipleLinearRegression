install.packages(c("neuralnet", "NeuralNetTools"))
library("assertthat", lib.loc="~/R/win-library/3.4")
detach("package:assertthat", unload=TRUE)
print("Hello World!")
data
dataset
datasets
library("compiler", lib.loc="C:/Program Files/R/R-3.4.3/library")
detach("package:compiler", unload=TRUE)
r<-c(1,2,3,4)
r
r[2]
r[0]
boxplot(r)
r[1] += 22
r[1] = 22 + r[1]
r
boxplot(r)
q()
setwd("C:/Users/test/Desktop/MachineLearning/Part 2 - Regression/Section 6 - Polynomial Regression")
setwd("C:/Users/test/Desktop/MachineLearning/Part 2 - Regression/Section 6 - Polynomial Regression")
setwd("C:/Users/test/Desktop/MachineLearning/Part 2 - Regression/Section 5 - Multiple Linear Regression")
# Multiple Linear Regression model
# Importing the data sets
dataset = read.csv('50_Startups.csv')
# Encoding categorical data
dataset$State = factor(dataset$State,
levels = c('New York', 'California', 'Florida'),
labels = c(1, 2, 3))
# Splitting the data sets into training and testing sets
library(caTools)
set.seed(123)
split = sample.split(dataset$Profit, SplitRatio = 0.8)
trainSet = subset(dataset, split == TRUE)
testSet = subset(dataset, split == FALSE)
# Fitting Multiple linear regression to the training set
# This is the long way of writing it
#regressor = lm(formula = Profit ~ R.D.Spend + Administration + Marketing.Spend + State)
# Simpler way
regressor = lm(formula = Profit ~ .,
data = trainSet)
# Predicting the Test set result
y_pred = predict(regressor, newdata = testSet)
# Visualizing the sets
library(ggplot2)
ggplot() +
geom_point(aes(x = trainSet$Profit, y = trainSet$R.D.Spend),
color = 'red') +
geom_line(aes(x = trainSet$Profit, y = predict(regressor, newdata = trainSet)),
color = 'purple') +
ggtitle('R&D Spend vs Profit (Training Set)') +
xlab('Profit') +
ylab('R&D Spend')
ggplot() +
geom_point(aes(x = testSet$Profit, y = testSet$R.D.Spend),
color = 'orange') +
geom_line(aes(x = trainSet$Profit, y = predict(regressor, newdata = trainSet)),
color = 'green') +
ggtitle('R&D Spend vs Profit (Testing Set)') +
xlab('Profit') +
ylab('R&D Spend')
View(dataset)
View(dataset)
regressor = lm(formula = Profit ~ R.D.Spend + Administrastion + Marketing.Spend + State,
data = dataset)
# Building the optimal model using Backward Elimination
regressor = lm(formula = Profit ~ R.D.Spend + Administration + Marketing.Spend + State,
data = dataset)
summary(regressor)
# Building the optimal model using Backward Elimination
regressor = lm(formula = Profit ~ R.D.Spend + Administration + Marketing.Spend,
data = dataset)
summary(regressor)
# Building the optimal model using Backward Elimination
regressor = lm(formula = Profit ~ R.D.Spend + Marketing.Spend,
data = dataset)
summary(regressor)
# Building the optimal model using Backward Elimination
regressor = lm(formula = Profit ~ R.D.Spend,
data = dataset)
summary(regressor)
# Building the optimal model using Backward Elimination
regressor = lm(formula = Profit ~ Marketing.Spend,
data = dataset)
summary(regressor)
# Building the optimal model using Backward Elimination
regressor = lm(formula = Profit ~ Marketing.Spend + R.D.Spend,
data = dataset)
summary(regressor)
setwd("C:/Users/test/Desktop/MachineLearning/Part 2 - Regression/Section 5 - Multiple Linear Regression/multipleLinearRegression/MultipleLinearRegression")
# Importing the data sets
dataset = read.csv('50_Startups.csv')
# Encoding categorical data
dataset$State = factor(dataset$State,
levels = c('New York', 'California', 'Florida'),
labels = c(1, 2, 3))
# Splitting the data sets into training and testing sets
library(caTools)
set.seed(123)
split = sample.split(dataset$Profit, SplitRatio = 0.8)
trainSet = subset(dataset, split == TRUE)
testSet = subset(dataset, split == FALSE)
# Predicting the Test set result
y_pred = predict(regressor, newdata = testSet)
backwardElimination <- function(x, sl){
numVariables = length(x)
for(i in c(1:numVariables)){
regressor = lm(formula = Profit ~ ., data = x)
maxVariable = max(coef(summary(regressor))[c(2:numVariables), "Pr(>|t|)"])
if(maxVariable > sl){
j = which(coef(summary(regressor))[c(2:numVariables), "Pr(>|t|)"])
x = x[, -j]
}
numVariables = numVariables - 1
}
return(summary(regressor))
}
SL = 0.05
dataset = dataset[, c(1, 2, 3, 4, 5)]
backwardElimination(trainSet, SL)
View(backwardElimination)
View(backwardElimination)
# Building the optimal model using Backward Elimination
backwardElimination <- function(x, sl){
numVariables = length(x)
for(i in c(1:numVariables)){
regressor = lm(formula = Profit ~ ., data = x)
maxVariable = max(coef(summary(regressor))[c(2:numVariables), "Pr(>|t|)"])
if(maxVariable > sl){
j = which(coef(summary(regressor))[c(2:numVariables), "Pr(>|t|)"] == maxVariable)
x = x[, -j]
}
numVariables = numVariables - 1
}
return(summary(regressor))
}
SL = 0.05
dataset = dataset[, c(1, 2, 3, 4, 5)]
backwardElimination(trainSet, SL)
